The Wine Quality dataset is a dataset that contains wine chemical properties with each column containing qualities of the wines and how they correlate with the final quality target of the wine.

Project Approach
I conducted an Exploratory Data Analysis (EDA) on a  white Wine quality dataset. The objective is to understand data and explore the data indepth by checking for missing values and duplication in the dataset.
The following were the premiliminary cleaning and insight discovered from the Wine dataset
1. The dataset has 4898 rows and 12 columns
2. The data was clean as there were no missing values in the dataset
3. The initial data type of the data were all "float 64", apart from the wine quality that was int64.
4. There were about 937 duplicate rows in the data

There was not much cleaning to do on the data as it was very clean therefore the duplicate values which amount to about 937 were dropped which was the only cleaning done on the dataset.

A univariate analysis was perfomed on the wine properties column where the numerical features of the columns were identified, the correlation of the features column with the data was checked with the target (quality). The quality column was mapped to Best, Good, Average, Bad and poor then splitted the dataset was splitted and MinMax scaler was applied. A Base model was built using Decison Treee and other multiple 3 models were trained and the were compared. The model that performed bast was selected based on balance of the metrics and was optimized using RandomSearch and the model was retrained using optimal parameters found. the model was reevaluated using same classification metrics used before tuning

2. Indicate what your metric indicate about the model is more precise for "Good" Wines or "Bad" Wines

 precision    recall  f1-score   support

     Average       0.58      0.51      0.55       235
         Bad       0.57      0.11      0.19        35
        Best       1.00      0.00      0.00        27
        Good       0.74      0.86      0.79       496

    accuracy                           0.69       793
   macro avg       0.72      0.37      0.38       793
weighted avg       0.69      0.69      0.67       793

After the hyperparameter tuning, the SVM model maintained an overall accuracy of  69%, which is roughly the same as before optimization. But, looking deeper into the precision, recall, and F1-scores, the results show that while the model performs quite well for the *Good* class (with high recall and F1-score), its performance on the *Bad* and *Best* classes remains poor. This suggests that the optimization didn’t significantly improve the model’s ability to generalize across all categories. This reinforced what the model was already good at.
The tuning helped stabilize performance but didn’t lead to a meaningful boost in accuracy or class balance.

The  base model used was decision tree. The decision tree model achieved an accuracy of about 59.27%, meaning it correctly classified a little more than half of the test samples. From the confusion matrix, it’s clear that the model performs well for some classes but struggles with others. For example, the majority of the samples in class 3 were correctly predicted, as shown by the large value along the diagonal (354), but there’s confusion between classes 0 and 3, where a number of samples from class 0 were incorrectly classified as class 3 and vice versa.
This shows that while the model can recognize certain patterns well, its overall predictive ability is limited—possibly due to overlapping features between classes or insufficient feature discrimination. In simple terms, the decision tree has learned some useful distinctions but is not generalizing well enough to make consistently accurate predictions across all categories.

The features that influence the quality prediction most is the palcohol feature because it correlates most to the target. the pH also correlates with the target well.

the result can help wine producers maximizze profit

